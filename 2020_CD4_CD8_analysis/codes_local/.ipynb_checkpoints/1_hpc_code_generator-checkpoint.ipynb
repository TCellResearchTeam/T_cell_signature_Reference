{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/pipkin/Yolanda/SARS2_Sc'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_dir = os.getcwd()\n",
    "base_dir = code_dir.replace(\"/z_References/codes_local\", \"\")\n",
    "base_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Fastq dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----- First trial\n",
    "wkdir = base_dir + '/z_References/codes_hpc'\n",
    "os.chdir(wkdir)\n",
    "\n",
    "input_dir = base_dir + '/z_References/0_Analysis_from_GEO'\n",
    "sra_files = glob.glob(\"%s/*SraRunTable.csv\"%input_dir)\n",
    "\n",
    "srr_info = []\n",
    "for i in sra_files:\n",
    "    i_df = pd.read_csv(i)\n",
    "    srr_info += i_df.iloc[:,0].values.tolist()\n",
    "\n",
    "dump_script = \"0_0_fastq-dump.sh\"\n",
    "dump_dir = '/gpfs/group/pipkin/hdiao/SARS_Sc_references/fastq'\n",
    "\n",
    "with open(dump_script, \"w\") as fout:\n",
    "    wfout = csv.writer(fout, delimiter=\" \")\n",
    "    wfout.writerow([\"#!/bin/bash\"])\n",
    "    wfout.writerow([\"#PBS\", \"-l\", \"nodes=1:ppn=16\"])\n",
    "    wfout.writerow([\"#PBS\", \"-l\", \"mem=32gb\"])\n",
    "    wfout.writerow([])\n",
    "    wfout.writerow([\"cd\", dump_dir])\n",
    "    wfout.writerow([\"module\", \"load\", \"sra-tools\"])\n",
    "    wfout.writerow([])\n",
    "    for i in range(0, len(srr_info)):\n",
    "        if ((i+1) % 16 != 0):\n",
    "            wfout.writerow([\"fastq-dump\", \"-I\", \"--split-files\", srr_info[i], \"&\"])\n",
    "        else:\n",
    "            wfout.writerow([\"fastq-dump\", \"-I\", \"--split-files\", srr_info[i]])\n",
    "            wfout.writerow([\"wait\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----- Redo\n",
    "wkdir = base_dir + '/z_References/codes_hpc'\n",
    "os.chdir(wkdir)\n",
    "\n",
    "input_dir = base_dir + '/z_References/0_Analysis_from_GEO'\n",
    "sra_files = glob.glob(\"%s/*SraRunTable_redo.csv\"%input_dir)\n",
    "\n",
    "srr_info = []\n",
    "for i in sra_files:\n",
    "    i_df = pd.read_csv(i)\n",
    "    srr_info += i_df.iloc[:,0].values.tolist()\n",
    "\n",
    "dump_script = \"0_0_fastq-dump.redo.sh\"\n",
    "dump_dir = '/gpfs/group/pipkin/hdiao/SARS_Sc_references/fastq_redo'\n",
    "\n",
    "with open(dump_script, \"w\") as fout:\n",
    "    wfout = csv.writer(fout, delimiter=\" \")\n",
    "    wfout.writerow([\"#!/bin/bash\"])\n",
    "    wfout.writerow([\"#PBS\", \"-l\", \"nodes=1:ppn=16\"])\n",
    "    wfout.writerow([\"#PBS\", \"-l\", \"mem=32gb\"])\n",
    "    wfout.writerow([])\n",
    "    wfout.writerow([\"cd\", dump_dir])\n",
    "    wfout.writerow([\"module\", \"load\", \"sra-tools\"])\n",
    "    wfout.writerow([])\n",
    "    for i in range(0, len(srr_info)):\n",
    "        if ((i+1) % 16 != 0):\n",
    "            wfout.writerow([\"fastq-dump\", \"-I\", \"--split-files\", srr_info[i], \"&\"])\n",
    "        else:\n",
    "            wfout.writerow([\"fastq-dump\", \"-I\", \"--split-files\", srr_info[i]])\n",
    "            wfout.writerow([\"wait\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Salmon quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----- First trial\n",
    "wkdir = base_dir + '/z_References/codes_hpc'\n",
    "os.chdir(wkdir)\n",
    "\n",
    "input_dir = base_dir + '/z_References/0_Analysis_from_GEO'\n",
    "\n",
    "info_file = base_dir + '/z_References/codes_local/GEO_dataset_info.csv'\n",
    "info_df = pd.read_csv(info_file).set_index('Dataset')\n",
    "\n",
    "for ds in info_df.index.values:\n",
    "    ds_out = \"0_1_salmon_%s.sh\"%ds\n",
    "\n",
    "    hpc_wkdir = \"/gpfs/group/pipkin/hdiao/SARS_Sc_references/salmon\"\n",
    "    hpc_inputdir = \"/gpfs/group/pipkin/hdiao/SARS_Sc_references/fastq\"\n",
    "    hpc_hs_idx = \"/gpfs/group/pipkin/hdiao/ref_resources/hs/release100/GRCh38.salmon.index\"\n",
    "    hpc_mm_idx = \"/gpfs/group/pipkin/hdiao/ref_resources/mm/release100/GRCm38.salmon.index\"\n",
    "    with open(ds_out, \"w\") as fout:\n",
    "        ds_run = input_dir + \"/\" + ds + '_SraRunTable.csv'\n",
    "        ds_run_df = pd.read_csv(ds_run)\n",
    "        runs = ds_run_df.iloc[:,0].values\n",
    "\n",
    "        wfout = csv.writer(fout, delimiter=\"|\")\n",
    "        wfout.writerow([\"#!/bin/bash\"])\n",
    "        wfout.writerow([\"#PBS -l nodes=1:ppn=12\"])\n",
    "        wfout.writerow([\"#PBS -l mem=32gb\"])\n",
    "        wfout.writerow([])\n",
    "        wfout.writerow([\"###----- Load module\"])\n",
    "        wfout.writerow([\"module load salmon\"])\n",
    "        wfout.writerow([])\n",
    "        wfout.writerow([\"###----- Working directory\"])\n",
    "        wfout.writerow([\"cd %s\"%hpc_wkdir])\n",
    "        wfout.writerow([\"mkdir %s\"%ds])\n",
    "        wfout.writerow([\"cd %s\" %ds])\n",
    "        wfout.writerow([])\n",
    "        wfout.writerow([\"###----- Reference\"])\n",
    "        if info_df.loc[ds][1] == \"Human\":\n",
    "            wfout.writerow([\"salmon_index=%s\"%hpc_hs_idx])\n",
    "        elif info_df.loc[ds][1] == \"Mouse\":\n",
    "            wfout.writerow([\"salmon_index=%s\"%hpc_mm_idx])\n",
    "        wfout.writerow([])\n",
    "        wfout.writerow([\"# Run\"])\n",
    "        if info_df.loc[ds][0] == \"Single\":\n",
    "            for run in runs:\n",
    "                run_file = hpc_inputdir + \"/\" + run\n",
    "                wfout.writerow([\"salmon quant -i $salmon_index -l A -r %s_1.fastq  -p 12 --validateMappings -o %s\" %(run_file, run)])\n",
    "        elif info_df.loc[ds][0] == \"Paired\":\n",
    "            for run in runs:\n",
    "                run_file = hpc_inputdir + \"/\" + run\n",
    "                wfout.writerow([\"salmon quant -i $salmon_index -l A -1 %s_1.fastq -2 %s_2.fastq -p 12 --validateMappings -o %s\" %(run_file, run_file, run)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "###----- Redo\n",
    "wkdir = base_dir + '/z_References/codes_hpc'\n",
    "os.chdir(wkdir)\n",
    "\n",
    "input_dir = base_dir + '/z_References/0_Analysis_from_GEO'\n",
    "\n",
    "info_file = base_dir + '/z_References/codes_local/GEO_dataset_info.csv'\n",
    "info_df = pd.read_csv(info_file).set_index('Dataset')\n",
    "\n",
    "for ds in info_df.index.values:\n",
    "    ds_out = \"0_1_salmon_%s.redo.sh\"%ds\n",
    "    ds_run = input_dir + \"/\" + ds + '_SraRunTable_redo.csv'\n",
    "    \n",
    "    if os.path.exists(ds_run):\n",
    "        hpc_wkdir = \"/gpfs/group/pipkin/hdiao/SARS_Sc_references/salmon\"\n",
    "        hpc_inputdir = \"/gpfs/group/pipkin/hdiao/SARS_Sc_references/fastq_redo\"\n",
    "        hpc_hs_idx = \"/gpfs/group/pipkin/hdiao/ref_resources/hs/release100/GRCh38.salmon.index\"\n",
    "        hpc_mm_idx = \"/gpfs/group/pipkin/hdiao/ref_resources/mm/release100/GRCm38.salmon.index\"\n",
    "\n",
    "        with open(ds_out, \"w\") as fout:\n",
    "            ds_run_df = pd.read_csv(ds_run)\n",
    "            runs = ds_run_df.iloc[:,0].values\n",
    "\n",
    "            wfout = csv.writer(fout, delimiter=\"|\")\n",
    "            wfout.writerow([\"#!/bin/bash\"])\n",
    "            wfout.writerow([\"#PBS -l nodes=1:ppn=12\"])\n",
    "            wfout.writerow([\"#PBS -l mem=32gb\"])\n",
    "            wfout.writerow([])\n",
    "            wfout.writerow([\"###----- Load module\"])\n",
    "            wfout.writerow([\"module load salmon\"])\n",
    "            wfout.writerow([])\n",
    "            wfout.writerow([\"###----- Working directory\"])\n",
    "            wfout.writerow([\"cd %s\"%hpc_wkdir])\n",
    "            wfout.writerow([\"mkdir %s\"%ds])\n",
    "            wfout.writerow([\"cd %s\" %ds])\n",
    "            wfout.writerow([])\n",
    "            wfout.writerow([\"###----- Reference\"])\n",
    "            if info_df.loc[ds][1] == \"Human\":\n",
    "                wfout.writerow([\"salmon_index=%s\"%hpc_hs_idx])\n",
    "            elif info_df.loc[ds][1] == \"Mouse\":\n",
    "                wfout.writerow([\"salmon_index=%s\"%hpc_mm_idx])\n",
    "            wfout.writerow([])\n",
    "            wfout.writerow([\"# Run\"])\n",
    "            if info_df.loc[ds][0] == \"Single\":\n",
    "                for run in runs:\n",
    "                    run_file = hpc_inputdir + \"/\" + run\n",
    "                    wfout.writerow([\"salmon quant -i $salmon_index -l A -r %s_1.fastq  -p 12 --validateMappings -o %s\" %(run_file, run)])\n",
    "            elif info_df.loc[ds][0] == \"Paired\":\n",
    "                for run in runs:\n",
    "                    run_file = hpc_inputdir + \"/\" + run\n",
    "                    wfout.writerow([\"salmon quant -i $salmon_index -l A -1 %s_1.fastq -2 %s_2.fastq -p 12 --validateMappings -o %s\" %(run_file, run_file, run)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check salmon output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incomplete number: 0\n"
     ]
    }
   ],
   "source": [
    "salmon_dir = base_dir + '/z_References/1_salmon'\n",
    "\n",
    "redo_n = 0\n",
    "for ds in info_df.index.values:\n",
    "    ds_out = \"0_1_salmon_%s.sh\"%ds\n",
    "    ds_run = input_dir + \"/\" + ds + '_SraRunTable.csv'\n",
    "    ds_run_df = pd.read_csv(ds_run)\n",
    "    runs = ds_run_df.iloc[:,0].values\n",
    "\n",
    "    ds_salmon_files = glob.glob(\"%s/%s/*/quant.sf\"%(salmon_dir, ds), recursive=True)\n",
    "    ds_salmon_files_runs = [x.split(\"/\")[-2] for x in ds_salmon_files]\n",
    "    incomplete_runs = list(set(runs) - set(ds_salmon_files_runs))\n",
    "    \n",
    "    if len(incomplete_runs) >= 1:\n",
    "        redo_n += 1\n",
    "        print(incomplete_runs)\n",
    "        ds_run_df_redo = ds_run_df.set_index(ds_run_df.columns[0]).loc[incomplete_runs]\n",
    "        ds_run_redo = input_dir + \"/\" + ds + '_SraRunTable_redo2.csv'\n",
    "        ds_run_df_redo.to_csv(ds_run_redo)\n",
    "        \n",
    "print(\"Incomplete number: %s\"%redo_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
